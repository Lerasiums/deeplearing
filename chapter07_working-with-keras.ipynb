{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "This is a companion notebook for the book [Deep Learning with Python, Second Edition](https://www.manning.com/books/deep-learning-with-python-second-edition?a_aid=keras&a_bid=76564dff). For readability, it only contains runnable code blocks and section titles, and omits everything else in the book: text paragraphs, figures, and pseudocode.\n",
    "\n",
    "**If you want to be able to follow what's going on, I recommend reading the notebook side by side with your copy of the book.**\n",
    "\n",
    "This notebook was generated for TensorFlow 2.6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "# Working with Keras: A deep dive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## A spectrum of workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Different ways to build Keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The `Sequential` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation=\"relu\"),\n",
    "    layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Incrementally building a Sequential model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Calling a model for the first time to build it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_2/kernel:0' shape=(3, 64) dtype=float32, numpy=\n",
       " array([[-0.29578775, -0.19045398, -0.03761965, -0.18102568,  0.07118598,\n",
       "          0.24152845,  0.0322603 , -0.2531932 , -0.15044883, -0.04497492,\n",
       "          0.1784392 , -0.0224798 , -0.2646321 ,  0.18611512,  0.0530194 ,\n",
       "         -0.15972385,  0.22553438,  0.18906775,  0.28362197,  0.03428116,\n",
       "          0.1817162 ,  0.1076166 , -0.1221672 ,  0.17108363,  0.05750987,\n",
       "          0.19051903, -0.09764209,  0.04266763, -0.06521426, -0.16700222,\n",
       "         -0.14176056, -0.2989919 , -0.0678544 , -0.19727656, -0.01713407,\n",
       "         -0.11646689,  0.16653866, -0.20241658, -0.2359224 ,  0.19915444,\n",
       "         -0.04380447,  0.07637328, -0.19788659,  0.2498442 , -0.01577714,\n",
       "          0.28504163,  0.22652578,  0.26953745, -0.00032392,  0.20643169,\n",
       "         -0.17439994,  0.28364795,  0.2778111 , -0.00712818,  0.04860416,\n",
       "         -0.03102458, -0.00439942, -0.11721455,  0.01234981, -0.04460755,\n",
       "          0.26761413,  0.16749707,  0.14527214,  0.18799019],\n",
       "        [ 0.19505551, -0.27793533,  0.25355083,  0.15070197, -0.23573127,\n",
       "         -0.15496184, -0.01457906, -0.23915565, -0.15241367, -0.12218226,\n",
       "          0.03941989, -0.00705498, -0.2258963 ,  0.06083995, -0.29183182,\n",
       "          0.00739929, -0.02379394,  0.12160164, -0.10487337,  0.14629954,\n",
       "         -0.07348984,  0.13621244, -0.01254481,  0.25351447, -0.05917242,\n",
       "          0.06510895,  0.23159331, -0.04277971,  0.19514477, -0.0448069 ,\n",
       "         -0.18499076, -0.16105363, -0.10231785, -0.16015029, -0.2788799 ,\n",
       "          0.16542622,  0.10964829,  0.15778199, -0.28803942,  0.1513663 ,\n",
       "          0.03256994, -0.21881843,  0.26975316,  0.09038085, -0.18890524,\n",
       "         -0.10834406,  0.2918365 ,  0.00118709,  0.01913437, -0.08993386,\n",
       "          0.1459294 ,  0.07738885,  0.08397499, -0.0396063 , -0.2067508 ,\n",
       "         -0.19004023,  0.16305876,  0.2924798 , -0.02212507, -0.29345697,\n",
       "         -0.2637456 , -0.13493311,  0.03344789,  0.22328222],\n",
       "        [-0.01770264, -0.06366824, -0.27446392,  0.14725932,  0.29722488,\n",
       "         -0.19233504, -0.13643727, -0.16999052, -0.08173947, -0.20445362,\n",
       "          0.24187016,  0.14322796, -0.26966166, -0.02337506,  0.11287856,\n",
       "          0.04122239,  0.1464057 ,  0.26258594,  0.28498083, -0.24006905,\n",
       "          0.16449365,  0.12732476,  0.22343725,  0.18150651, -0.22240263,\n",
       "         -0.18788825,  0.29256004, -0.22352585, -0.23577729,  0.05023357,\n",
       "          0.05916598, -0.2757681 ,  0.16019288, -0.18797807,  0.01443544,\n",
       "         -0.13646352, -0.17976913, -0.13541429,  0.01925632, -0.25158346,\n",
       "         -0.13363637, -0.169634  , -0.16367921,  0.05939686, -0.21875292,\n",
       "          0.17549393, -0.2865103 ,  0.28221154, -0.17690316,  0.10564905,\n",
       "          0.01854435, -0.18737334, -0.18296912, -0.28394672, -0.2479901 ,\n",
       "         -0.15564913, -0.01778442, -0.18807268, -0.11057509,  0.20105618,\n",
       "         -0.19485867,  0.06309345, -0.17451361, -0.1976144 ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_2/bias:0' shape=(64,) dtype=float32, numpy=\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/kernel:0' shape=(64, 10) dtype=float32, numpy=\n",
       " array([[ 1.65076077e-01, -2.15972632e-01,  2.84070820e-01,\n",
       "         -2.10499361e-01,  1.59215748e-01,  3.83157730e-02,\n",
       "         -1.79484233e-01, -2.16022611e-01,  1.79128766e-01,\n",
       "          2.59693265e-02],\n",
       "        [ 1.79308057e-02, -1.00231558e-01,  3.51827741e-02,\n",
       "          2.06522405e-01,  2.63107330e-01, -3.76147479e-02,\n",
       "         -3.74981910e-02,  1.78020418e-01, -1.49477541e-01,\n",
       "         -5.03609926e-02],\n",
       "        [-3.39042842e-02, -2.36273780e-01,  1.28829151e-01,\n",
       "          8.68400931e-02,  1.94774538e-01, -1.76979601e-01,\n",
       "          1.05629861e-02,  2.75804251e-01, -1.03790432e-01,\n",
       "         -1.62042588e-01],\n",
       "        [ 1.33352339e-01,  3.90028059e-02,  2.66934842e-01,\n",
       "         -2.36181915e-02,  1.25713855e-01, -1.46917030e-01,\n",
       "         -2.58012146e-01, -1.22646421e-01,  8.91378820e-02,\n",
       "          2.55542785e-01],\n",
       "        [ 3.38255167e-02,  4.73519564e-02, -1.89182669e-01,\n",
       "         -1.02000207e-01, -1.34530544e-01,  9.79240835e-02,\n",
       "         -2.99502909e-02, -9.23311710e-02,  1.05817527e-01,\n",
       "          2.52417535e-01],\n",
       "        [-2.61375755e-01, -6.17490411e-02,  5.28794825e-02,\n",
       "          2.61357427e-02, -1.09378114e-01, -8.51156414e-02,\n",
       "         -1.29393935e-02, -2.16014981e-02,  1.66480213e-01,\n",
       "          1.22518301e-01],\n",
       "        [ 1.94622278e-02, -9.41027403e-02, -4.64230925e-02,\n",
       "         -7.04128444e-02, -8.75111818e-02, -1.85850531e-01,\n",
       "          1.96401775e-02,  4.86588180e-02,  1.59981132e-01,\n",
       "         -1.96968615e-02],\n",
       "        [ 2.91149020e-02, -2.29873881e-01, -1.88136965e-01,\n",
       "         -1.53906956e-01, -1.45005584e-02,  1.32856071e-02,\n",
       "          1.74341381e-01,  3.04401815e-02, -2.19987601e-01,\n",
       "         -2.53053784e-01],\n",
       "        [-1.82013303e-01, -3.35252583e-02, -1.56257898e-01,\n",
       "         -4.64319140e-02,  1.80116624e-01, -1.36997566e-01,\n",
       "          9.76623595e-02, -2.20175654e-01, -1.03249431e-01,\n",
       "          1.88313812e-01],\n",
       "        [-8.22629482e-02, -2.68157810e-01,  1.49552763e-01,\n",
       "         -1.12316623e-01, -1.14691660e-01,  1.92095578e-01,\n",
       "          2.66160369e-02,  2.41985410e-01, -1.49337053e-02,\n",
       "          1.29113466e-01],\n",
       "        [ 7.45075047e-02,  1.65730715e-04, -1.71899259e-01,\n",
       "         -2.69960940e-01,  1.00287557e-01,  1.43165022e-01,\n",
       "          2.11626589e-01,  5.26425540e-02,  7.09035397e-02,\n",
       "          6.04969561e-02],\n",
       "        [-1.88271254e-01,  2.43805140e-01, -1.70031294e-01,\n",
       "         -9.39281285e-02, -1.81596935e-01, -7.16436803e-02,\n",
       "         -1.29171580e-01, -1.66869015e-01,  2.31839448e-01,\n",
       "         -1.20141178e-01],\n",
       "        [ 1.90753013e-01,  1.69414043e-01, -2.73139477e-02,\n",
       "          8.06224644e-02, -2.63757110e-02, -1.61709860e-01,\n",
       "          3.97474170e-02, -5.24318814e-02,  7.09449053e-02,\n",
       "         -6.51842356e-02],\n",
       "        [-8.77913833e-03,  6.37565255e-02, -2.42840618e-01,\n",
       "         -2.43075520e-01, -4.53010201e-03, -7.76354969e-02,\n",
       "         -1.63073614e-01,  1.90939426e-01,  1.02450848e-02,\n",
       "         -2.44815722e-01],\n",
       "        [-2.29052007e-01,  2.07805663e-01, -1.13006711e-01,\n",
       "          2.15607733e-01,  1.61406457e-01, -2.14384049e-01,\n",
       "          2.54598886e-01, -5.92231005e-02, -4.68219370e-02,\n",
       "         -2.22465694e-02],\n",
       "        [ 1.33910775e-01,  2.18504876e-01,  1.00946754e-01,\n",
       "         -2.28954867e-01, -2.39696413e-01, -2.14104682e-01,\n",
       "         -2.39319086e-01,  2.14851111e-01, -9.27282572e-02,\n",
       "          4.86066639e-02],\n",
       "        [-1.67437315e-01,  1.47112966e-01, -6.02343082e-02,\n",
       "         -1.65739417e-01,  1.15390569e-01,  3.76625359e-02,\n",
       "         -2.21329227e-01, -2.00368002e-01,  2.17245907e-01,\n",
       "          2.62357295e-02],\n",
       "        [-5.85773289e-02, -2.27795243e-01, -2.65784740e-01,\n",
       "          2.49883920e-01,  8.81613493e-02, -2.00529993e-02,\n",
       "          2.03047842e-01, -2.22541049e-01,  1.98489785e-01,\n",
       "          8.82959068e-02],\n",
       "        [-4.81019914e-02,  2.01350003e-01, -1.93342298e-01,\n",
       "          4.59390879e-03, -7.30445683e-02,  1.00308269e-01,\n",
       "          1.48650378e-01,  1.02481604e-01,  7.73447156e-02,\n",
       "         -2.47179270e-01],\n",
       "        [-1.69513106e-01,  2.61165470e-01, -2.30753452e-01,\n",
       "         -2.77094394e-01,  1.85579509e-01, -2.60460407e-01,\n",
       "         -1.91471130e-01, -1.58913448e-01, -2.44741857e-01,\n",
       "         -1.63523927e-01],\n",
       "        [-2.62457132e-02, -1.43723473e-01, -1.69751942e-02,\n",
       "         -1.20122775e-01, -9.00272131e-02,  1.68426275e-01,\n",
       "         -2.01462239e-01,  1.50514126e-01,  2.46274859e-01,\n",
       "          1.50196761e-01],\n",
       "        [-9.31206495e-02, -1.62624061e-01,  2.92893946e-02,\n",
       "         -2.22661957e-01, -2.66469270e-01,  2.51054019e-01,\n",
       "         -2.79312193e-01,  1.53892577e-01,  1.65189713e-01,\n",
       "         -4.91800010e-02],\n",
       "        [ 1.70440048e-01, -2.78863460e-01, -1.82546228e-01,\n",
       "         -2.28191108e-01,  1.35362327e-01,  7.35311806e-02,\n",
       "          1.81215882e-01,  1.14867479e-01,  9.61041749e-02,\n",
       "         -1.68876097e-01],\n",
       "        [-2.04531774e-01,  5.48434258e-03, -2.11795837e-01,\n",
       "          1.27784550e-01,  2.75806874e-01, -1.47324502e-01,\n",
       "         -1.50383040e-01, -1.13783434e-01,  1.82706386e-01,\n",
       "         -2.20309123e-01],\n",
       "        [-2.56821901e-01, -5.27391434e-02,  1.44662976e-01,\n",
       "          4.98304367e-02, -1.92846566e-01,  2.28731781e-01,\n",
       "         -7.07429945e-02, -1.24940053e-01, -1.36931986e-01,\n",
       "          8.73572230e-02],\n",
       "        [ 3.33809257e-02,  2.91953683e-02,  2.34474152e-01,\n",
       "         -1.69438958e-01, -2.37568289e-01, -7.00757056e-02,\n",
       "         -1.07712254e-01,  1.63387537e-01,  5.67074120e-02,\n",
       "          6.15079105e-02],\n",
       "        [-2.49667212e-01,  3.91848981e-02, -8.36011767e-02,\n",
       "         -1.57623351e-01, -2.61734426e-01, -9.89476442e-02,\n",
       "          1.02850795e-01, -1.70468226e-01,  1.16069615e-01,\n",
       "         -1.12442285e-01],\n",
       "        [ 2.56199628e-01, -1.83748543e-01,  2.17534691e-01,\n",
       "          1.26073807e-01,  1.82805091e-01, -1.58760965e-01,\n",
       "         -1.00340113e-01, -2.05568433e-01, -1.92320347e-02,\n",
       "          1.82036042e-01],\n",
       "        [ 1.20696038e-01, -1.53905198e-01,  6.72418773e-02,\n",
       "          4.70158160e-02,  8.95120800e-02,  2.26866931e-01,\n",
       "          1.26475364e-01, -1.80140182e-01, -1.24535441e-01,\n",
       "          1.56509012e-01],\n",
       "        [-1.12618595e-01,  1.28430992e-01, -7.38377869e-02,\n",
       "         -1.36278480e-01,  7.25582838e-02,  7.56576955e-02,\n",
       "         -1.66109502e-02, -2.37060145e-01, -8.26728642e-02,\n",
       "          1.27788812e-01],\n",
       "        [ 1.21028364e-01, -1.39689222e-01,  2.16378868e-02,\n",
       "         -1.62584007e-01,  2.29878515e-01,  6.05875254e-02,\n",
       "          1.62961394e-01, -2.04043105e-01, -6.39419258e-02,\n",
       "         -1.33813024e-01],\n",
       "        [ 2.58581549e-01, -2.70986408e-01,  1.37179375e-01,\n",
       "         -2.35082805e-01,  2.51264304e-01,  2.62743980e-01,\n",
       "          2.04654306e-01,  1.84112102e-01, -2.52303332e-01,\n",
       "          2.70647109e-02],\n",
       "        [ 2.67074853e-01,  2.34319240e-01,  8.69255066e-02,\n",
       "          2.64199942e-01,  7.73173571e-03, -1.16717666e-01,\n",
       "         -2.65486985e-01,  1.15689635e-02,  7.39360154e-02,\n",
       "         -2.67682105e-01],\n",
       "        [-1.77802891e-01, -6.33351356e-02, -2.75661528e-01,\n",
       "         -6.11852258e-02, -1.91052884e-01,  1.94342017e-01,\n",
       "          5.28261065e-02, -2.74353713e-01, -2.38528848e-01,\n",
       "          1.92632109e-01],\n",
       "        [-2.25394368e-02, -1.99150681e-01,  1.40965730e-01,\n",
       "          1.40414357e-01, -2.36684859e-01,  2.41826028e-01,\n",
       "         -1.09175742e-02, -2.06438169e-01, -1.82878226e-01,\n",
       "         -2.75093913e-01],\n",
       "        [-1.40925556e-01, -1.33495837e-01,  5.41265905e-02,\n",
       "         -1.65678918e-01, -2.79953808e-01, -5.92905134e-02,\n",
       "         -2.44263917e-01, -7.89821148e-03, -1.30774379e-01,\n",
       "          3.93969119e-02],\n",
       "        [-8.74070376e-02, -9.48249400e-02,  9.19670165e-02,\n",
       "          1.02937490e-01,  1.44369692e-01, -1.81169853e-01,\n",
       "         -1.22889668e-01,  2.23785192e-01,  1.11934274e-01,\n",
       "         -4.50670719e-02],\n",
       "        [-1.05830908e-01, -1.08207166e-02, -1.96087256e-01,\n",
       "          7.75978863e-02,  1.49099886e-01,  1.89782321e-01,\n",
       "          1.13310397e-01,  2.45189458e-01,  2.79424638e-01,\n",
       "          4.04717326e-02],\n",
       "        [ 2.03591377e-01, -2.82912970e-01,  1.37771904e-01,\n",
       "          2.39765912e-01, -1.92043453e-01,  7.94657171e-02,\n",
       "          1.36936307e-02, -1.88474238e-01, -3.22611034e-02,\n",
       "         -1.22847781e-01],\n",
       "        [ 2.99724936e-03,  2.02625096e-01, -2.03819275e-02,\n",
       "          2.65178293e-01, -2.38794774e-01, -1.71561852e-01,\n",
       "          2.41414160e-01, -1.93516314e-02,  2.36416608e-01,\n",
       "         -1.89283207e-01],\n",
       "        [ 5.23227751e-02,  5.11207283e-02,  1.83752149e-01,\n",
       "         -1.49156228e-01, -2.73282349e-01,  1.21021301e-01,\n",
       "          9.58141387e-02,  7.34078288e-02,  4.56638932e-02,\n",
       "         -7.82269388e-02],\n",
       "        [-2.83625722e-03, -1.27331108e-01,  3.03815007e-02,\n",
       "          1.92297488e-01,  8.96661878e-02,  2.12150693e-01,\n",
       "         -4.61829007e-02,  2.32505172e-01,  2.32692569e-01,\n",
       "         -1.88185871e-02],\n",
       "        [ 2.71733791e-01, -2.69837946e-01, -2.46681377e-01,\n",
       "         -1.44633457e-01,  2.09944785e-01,  2.10675061e-01,\n",
       "         -2.42138103e-01,  1.12533808e-01,  1.53993100e-01,\n",
       "         -1.65881038e-01],\n",
       "        [ 4.61321771e-02,  2.20669836e-01, -1.89099371e-01,\n",
       "          1.28021330e-01,  2.80229300e-01, -4.06833440e-02,\n",
       "          4.23833430e-02, -9.07226801e-02, -8.18184018e-03,\n",
       "          1.84321404e-02],\n",
       "        [ 8.51594508e-02,  8.21344256e-02,  1.59906864e-01,\n",
       "          1.08436018e-01,  1.82490557e-01,  2.04973668e-01,\n",
       "          2.43834764e-01, -9.11639482e-02,  2.18153089e-01,\n",
       "          1.99916869e-01],\n",
       "        [ 3.28022242e-02,  3.40232253e-03,  2.27552056e-02,\n",
       "         -1.70947939e-01,  2.65047818e-01, -6.10715747e-02,\n",
       "         -1.70615211e-01, -2.56773293e-01,  3.16708684e-02,\n",
       "         -2.63759434e-01],\n",
       "        [ 1.45951182e-01, -2.52599597e-01,  1.25372022e-01,\n",
       "         -1.22383833e-01,  5.18918037e-03, -1.06822222e-01,\n",
       "          2.29530782e-01, -1.28304362e-01,  9.29291248e-02,\n",
       "         -1.55116946e-01],\n",
       "        [ 2.82825828e-02,  2.72495151e-02, -1.70714125e-01,\n",
       "         -1.89167321e-01,  1.69904530e-02,  1.88831896e-01,\n",
       "         -2.31153190e-01,  7.32779801e-02,  9.30101871e-02,\n",
       "          3.38787436e-02],\n",
       "        [ 2.17037827e-01,  8.86701941e-02, -6.24313951e-02,\n",
       "          4.15259004e-02,  3.98669839e-02, -8.96206349e-02,\n",
       "         -2.59541959e-01,  2.60011166e-01,  1.90274537e-01,\n",
       "         -1.12462729e-01],\n",
       "        [-3.97613645e-03,  1.30216122e-01,  5.23191988e-02,\n",
       "         -2.29928732e-01, -7.79917091e-02, -2.79402137e-01,\n",
       "         -1.09802559e-01,  2.14692265e-01,  6.91220164e-02,\n",
       "         -1.23677388e-01],\n",
       "        [-2.26767883e-01, -1.71913251e-01,  1.29919648e-01,\n",
       "          2.21908242e-01, -2.76536673e-01, -1.82705432e-01,\n",
       "         -2.01299310e-01, -4.81165797e-02,  2.44095415e-01,\n",
       "          3.81652117e-02],\n",
       "        [ 1.44684583e-01, -2.02065021e-01, -1.07600987e-01,\n",
       "         -1.37432247e-01,  1.40381962e-01, -1.32687345e-01,\n",
       "         -1.54481173e-01, -4.00142968e-02,  1.04967028e-01,\n",
       "          2.30752975e-01],\n",
       "        [ 1.23398691e-01,  1.43615395e-01,  2.67769128e-01,\n",
       "          2.34929532e-01, -1.66445255e-01,  1.62523508e-01,\n",
       "         -7.66356289e-02, -4.58096415e-02, -1.97840840e-01,\n",
       "         -1.69284374e-01],\n",
       "        [-2.54847825e-01, -5.41171581e-02,  2.59122580e-01,\n",
       "          2.43452519e-01, -4.69120294e-02, -2.83347249e-01,\n",
       "          2.06112027e-01,  1.94364846e-01,  1.18165612e-02,\n",
       "          8.42192471e-02],\n",
       "        [-2.63664454e-01, -2.76136100e-02,  3.98382545e-02,\n",
       "         -1.70498237e-01, -1.38266385e-02,  5.94979227e-02,\n",
       "         -1.86324120e-01,  2.27471739e-01, -7.94035345e-02,\n",
       "          1.02582544e-01],\n",
       "        [ 2.57910579e-01,  2.61670381e-01, -1.70593411e-01,\n",
       "          2.03111261e-01, -2.12386668e-01,  2.28702992e-01,\n",
       "         -2.58163124e-01,  2.17871040e-01,  2.32417196e-01,\n",
       "         -1.04337931e-04],\n",
       "        [-7.53713995e-02, -7.13998824e-02, -1.82517856e-01,\n",
       "         -9.95348096e-02, -1.17058605e-01,  1.69987977e-02,\n",
       "         -1.91877872e-01, -1.34021297e-01, -2.69284159e-01,\n",
       "          1.72305644e-01],\n",
       "        [-2.05127984e-01,  2.59787709e-01, -1.98869482e-01,\n",
       "         -2.51979440e-01,  2.75921524e-02,  1.02344602e-01,\n",
       "         -2.30178162e-01,  1.93229467e-01, -1.21601269e-01,\n",
       "         -1.91209227e-01],\n",
       "        [-1.72266200e-01, -1.18185699e-01,  3.66312563e-02,\n",
       "         -2.52599806e-01, -2.39926621e-01,  3.34746838e-02,\n",
       "         -2.71738410e-01, -4.75874543e-03,  2.14824647e-01,\n",
       "         -4.09069657e-02],\n",
       "        [ 2.21200436e-01, -2.48920903e-01, -1.87983066e-01,\n",
       "         -2.18494043e-01,  2.43776143e-02, -2.54999280e-01,\n",
       "          1.04879707e-01, -2.66017079e-01, -3.55476737e-02,\n",
       "         -3.48685086e-02],\n",
       "        [ 2.05482572e-01,  9.90263820e-02,  1.16830289e-01,\n",
       "         -1.59798577e-01,  2.18389183e-01,  6.96954727e-02,\n",
       "         -1.42972469e-02, -2.17189282e-01, -1.66619122e-01,\n",
       "         -6.74306750e-02],\n",
       "        [ 7.00089037e-02, -2.65698940e-01, -1.60740465e-01,\n",
       "         -1.07942119e-01, -2.00132281e-01,  7.84485936e-02,\n",
       "          1.21926337e-01,  8.90913606e-03,  8.33992064e-02,\n",
       "         -1.46820083e-01],\n",
       "        [-1.23305768e-01,  2.69322067e-01, -1.60575032e-01,\n",
       "          9.71853733e-03,  1.08143747e-01,  1.52323931e-01,\n",
       "         -1.24734551e-01, -2.62263834e-01, -2.23993599e-01,\n",
       "         -5.14897108e-02],\n",
       "        [-2.70420074e-01,  2.84109980e-01,  2.08200842e-01,\n",
       "          2.32853919e-01, -9.44405794e-03, -5.64487427e-02,\n",
       "          3.36243808e-02,  1.94626212e-01,  2.24931151e-01,\n",
       "         -1.03513658e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_3/bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.build(input_shape=(None, 3))\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The summary method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Naming models and layers with the `name` argument**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_example_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_first_layer (Dense)       (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "my_last_layer (Dense)        (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential(name=\"my_example_model\")\n",
    "model.add(layers.Dense(64, activation=\"relu\", name=\"my_first_layer\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\", name=\"my_last_layer\"))\n",
    "model.build((None, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Specifying the input shape of your model in advance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(3,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                256       \n",
      "=================================================================\n",
      "Total params: 256\n",
      "Trainable params: 256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### The Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### A simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple Functional model with two `Dense` layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(3,), name=\"my_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = layers.Dense(64, activation=\"relu\")(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([None, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "my_input (InputLayer)        [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 906\n",
      "Trainable params: 906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Multi-input, multi-output models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A multi-input, multi-output Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "num_tags = 100\n",
    "num_departments = 4\n",
    "\n",
    "title = keras.Input(shape=(vocabulary_size,), name=\"title\")\n",
    "text_body = keras.Input(shape=(vocabulary_size,), name=\"text_body\")\n",
    "tags = keras.Input(shape=(num_tags,), name=\"tags\")\n",
    "\n",
    "features = layers.Concatenate()([title, text_body, tags])\n",
    "features = layers.Dense(64, activation=\"relu\")(features)\n",
    "\n",
    "priority = layers.Dense(1, activation=\"sigmoid\", name=\"priority\")(features)\n",
    "department = layers.Dense(\n",
    "    num_departments, activation=\"softmax\", name=\"department\")(features)\n",
    "\n",
    "model = keras.Model(inputs=[title, text_body, tags], outputs=[priority, department])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Training a multi-input, multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing lists of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 2s 5ms/step - loss: 37.0580 - priority_loss: 0.3366 - department_loss: 36.7214 - priority_mean_absolute_error: 0.5014 - department_accuracy: 0.2570\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 35.3162 - priority_loss: 0.3423 - department_loss: 34.9739 - priority_mean_absolute_error: 0.5072 - department_accuracy: 0.5492\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = 1280\n",
    "\n",
    "title_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "text_body_data = np.random.randint(0, 2, size=(num_samples, vocabulary_size))\n",
    "tags_data = np.random.randint(0, 2, size=(num_samples, num_tags))\n",
    "\n",
    "priority_data = np.random.random(size=(num_samples, 1))\n",
    "department_data = np.random.randint(0, 2, size=(num_samples, num_departments))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit([title_data, text_body_data, tags_data],\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate([title_data, text_body_data, tags_data],\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict([title_data, text_body_data, tags_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Training a model by providing dicts of input & target arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 5ms/step - loss: 48.6488 - priority_loss: 0.3423 - department_loss: 48.3065 - priority_mean_absolute_error: 0.5072 - department_accuracy: 0.2578\n",
      "40/40 [==============================] - 0s 3ms/step - loss: 37.2204 - priority_loss: 0.3423 - department_loss: 36.8781 - priority_mean_absolute_error: 0.5072 - department_accuracy: 0.2602\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss={\"priority\": \"mean_squared_error\", \"department\": \"categorical_crossentropy\"},\n",
    "              metrics={\"priority\": [\"mean_absolute_error\"], \"department\": [\"accuracy\"]})\n",
    "model.fit({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "          {\"priority\": priority_data, \"department\": department_data},\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data},\n",
    "               {\"priority\": priority_data, \"department\": department_data})\n",
    "priority_preds, department_preds = model.predict(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The power of the Functional API: Access to layer connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"ticket_classifier_with_shape_info.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Retrieving the inputs or outputs of a layer in a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x22ce185ef70>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x22ce185ef10>,\n",
       " <tensorflow.python.keras.engine.input_layer.InputLayer at 0x22ce185edf0>,\n",
       " <tensorflow.python.keras.layers.merge.Concatenate at 0x22ce1831a60>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x22ce1831970>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x22ce1817730>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x22cf7c233d0>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'title')>,\n",
       " <KerasTensor: shape=(None, 10000) dtype=float32 (created by layer 'text_body')>,\n",
       " <KerasTensor: shape=(None, 100) dtype=float32 (created by layer 'tags')>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 20100) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[3].output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a new model by reusing intermediate layer outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "features = model.layers[4].output\n",
    "difficulty = layers.Dense(3, activation=\"softmax\", name=\"difficulty\")(features)\n",
    "\n",
    "new_model = keras.Model(\n",
    "    inputs=[title, text_body, tags],\n",
    "    outputs=[priority, department, difficulty])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(new_model, \"updated_ticket_classifier.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Subclassing the Model class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Rewriting our previous example as a subclassed model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**A simple subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomerTicketModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_departments):\n",
    "        super().__init__()\n",
    "        self.concat_layer = layers.Concatenate()\n",
    "        self.mixing_layer = layers.Dense(64, activation=\"relu\")\n",
    "        self.priority_scorer = layers.Dense(1, activation=\"sigmoid\")\n",
    "        self.department_classifier = layers.Dense(\n",
    "            num_departments, activation=\"softmax\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        title = inputs[\"title\"]\n",
    "        text_body = inputs[\"text_body\"]\n",
    "        tags = inputs[\"tags\"]\n",
    "\n",
    "        features = self.concat_layer([title, text_body, tags])\n",
    "        features = self.mixing_layer(features)\n",
    "        priority = self.priority_scorer(features)\n",
    "        department = self.department_classifier(features)\n",
    "        return priority, department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = CustomerTicketModel(num_departments=4)\n",
    "\n",
    "priority, department = model(\n",
    "    {\"title\": title_data, \"text_body\": text_body_data, \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 1s 10ms/step - loss: 25.0024 - output_1_loss: 0.3371 - output_2_loss: 24.6653 - output_1_mean_absolute_error: 0.5021 - output_2_accuracy: 0.2062\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 34.3355 - output_1_loss: 0.3423 - output_2_loss: 33.9932 - output_1_mean_absolute_error: 0.5072 - output_2_accuracy: 0.0508\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=[\"mean_squared_error\", \"categorical_crossentropy\"],\n",
    "              metrics=[[\"mean_absolute_error\"], [\"accuracy\"]])\n",
    "model.fit({\"title\": title_data,\n",
    "           \"text_body\": text_body_data,\n",
    "           \"tags\": tags_data},\n",
    "          [priority_data, department_data],\n",
    "          epochs=1)\n",
    "model.evaluate({\"title\": title_data,\n",
    "                \"text_body\": text_body_data,\n",
    "                \"tags\": tags_data},\n",
    "               [priority_data, department_data])\n",
    "priority_preds, department_preds = model.predict({\"title\": title_data,\n",
    "                                                  \"text_body\": text_body_data,\n",
    "                                                  \"tags\": tags_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### Beware: What subclassed models don't support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Mixing and matching different components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a Functional model that includes a subclassed model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class Classifier(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        if num_classes == 2:\n",
    "            num_units = 1\n",
    "            activation = \"sigmoid\"\n",
    "        else:\n",
    "            num_units = num_classes\n",
    "            activation = \"softmax\"\n",
    "        self.dense = layers.Dense(num_units, activation=activation)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.dense(inputs)\n",
    "\n",
    "inputs = keras.Input(shape=(3,))\n",
    "features = layers.Dense(64, activation=\"relu\")(inputs)\n",
    "outputs = Classifier(num_classes=10)(features)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a subclassed model that includes a Functional model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(64,))\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(inputs)\n",
    "binary_classifier = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "class MyModel(keras.Model):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.dense = layers.Dense(64, activation=\"relu\")\n",
    "        self.classifier = binary_classifier\n",
    "\n",
    "    def call(self, inputs):\n",
    "        features = self.dense(inputs)\n",
    "        return self.classifier(features)\n",
    "\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Remember: Use the right tool for the job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Using built-in training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**The standard workflow: `compile()`, `fit()`, `evaluate()`, `predict()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2960 - accuracy: 0.9130 - val_loss: 0.1537 - val_accuracy: 0.9552\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1654 - accuracy: 0.9540 - val_loss: 0.1208 - val_accuracy: 0.9674\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1379 - accuracy: 0.9634 - val_loss: 0.1219 - val_accuracy: 0.9695\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.1131 - accuracy: 0.9708\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "images = images.reshape((60000, 28 * 28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28)).astype(\"float32\") / 255\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]\n",
    "\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)\n",
    "predictions = model.predict(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom metric by subclassing the `Metric` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class RootMeanSquaredError(keras.metrics.Metric):\n",
    "\n",
    "    def __init__(self, name=\"rmse\", **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.mse_sum = self.add_weight(name=\"mse_sum\", initializer=\"zeros\")\n",
    "        self.total_samples = self.add_weight(\n",
    "            name=\"total_samples\", initializer=\"zeros\", dtype=\"int32\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.one_hot(y_true, depth=tf.shape(y_pred)[1])\n",
    "        mse = tf.reduce_sum(tf.square(y_true - y_pred))\n",
    "        self.mse_sum.assign_add(mse)\n",
    "        num_samples = tf.shape(y_pred)[0]\n",
    "        self.total_samples.assign_add(num_samples)\n",
    "\n",
    "    def result(self):\n",
    "        return tf.sqrt(self.mse_sum / tf.cast(self.total_samples, tf.float32))\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.mse_sum.assign(0.)\n",
    "        self.total_samples.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 6s 3ms/step - loss: 0.2933 - accuracy: 0.9128 - rmse: 7.1846 - val_loss: 0.1415 - val_accuracy: 0.9586 - val_rmse: 7.3591\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1647 - accuracy: 0.9538 - rmse: 7.3585 - val_loss: 0.1276 - val_accuracy: 0.9646 - val_rmse: 7.4031\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1383 - accuracy: 0.9626 - rmse: 7.3882 - val_loss: 0.1025 - val_accuracy: 0.9712 - val_rmse: 7.4200\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9747 - rmse: 7.4325\n"
     ]
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\", RootMeanSquaredError()])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=3,\n",
    "          validation_data=(val_images, val_labels))\n",
    "test_metrics = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "#### The EarlyStopping and ModelCheckpoint callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Using the `callbacks` argument in the `fit()` method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2926 - accuracy: 0.9131 - val_loss: 0.1471 - val_accuracy: 0.9593\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1641 - accuracy: 0.9546 - val_loss: 0.1235 - val_accuracy: 0.9653\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1412 - accuracy: 0.9622 - val_loss: 0.1116 - val_accuracy: 0.9713\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1250 - accuracy: 0.9681 - val_loss: 0.1110 - val_accuracy: 0.9741\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1166 - accuracy: 0.9698 - val_loss: 0.1114 - val_accuracy: 0.9742\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1120 - accuracy: 0.9718 - val_loss: 0.1186 - val_accuracy: 0.9756\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1078 - accuracy: 0.9751 - val_loss: 0.1176 - val_accuracy: 0.9753\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1007 - accuracy: 0.9764 - val_loss: 0.1094 - val_accuracy: 0.9779\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0951 - accuracy: 0.9781 - val_loss: 0.1212 - val_accuracy: 0.9776\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0955 - accuracy: 0.9788 - val_loss: 0.1175 - val_accuracy: 0.9792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22e252bc100>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=2,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=\"checkpoint_path.keras\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "]\n",
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=callbacks_list,\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"checkpoint_path.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Writing your own callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Creating a custom callback by subclassing the `Callback` class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        plt.clf()\n",
    "        plt.plot(range(len(self.per_batch_losses)), self.per_batch_losses,\n",
    "                 label=\"Training loss for each batch\")\n",
    "        plt.xlabel(f\"Batch (epoch {epoch})\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"plot_at_epoch_{epoch}\")\n",
    "        self.per_batch_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2961 - accuracy: 0.9140 - val_loss: 0.1441 - val_accuracy: 0.9573\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1642 - accuracy: 0.9545 - val_loss: 0.1256 - val_accuracy: 0.9682\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1411 - accuracy: 0.9624 - val_loss: 0.1201 - val_accuracy: 0.9688\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1235 - accuracy: 0.9676 - val_loss: 0.1139 - val_accuracy: 0.9728\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.1162 - accuracy: 0.9709 - val_loss: 0.1161 - val_accuracy: 0.9739\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1124 - accuracy: 0.9726 - val_loss: 0.1141 - val_accuracy: 0.9751\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1060 - accuracy: 0.9746 - val_loss: 0.1104 - val_accuracy: 0.9762\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0983 - accuracy: 0.9770 - val_loss: 0.1169 - val_accuracy: 0.9770\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0956 - accuracy: 0.9774 - val_loss: 0.1188 - val_accuracy: 0.9780\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.0935 - accuracy: 0.9792 - val_loss: 0.1177 - val_accuracy: 0.9784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22e23d497c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          callbacks=[LossHistory()],\n",
    "          validation_data=(val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Monitoring and visualization with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2936 - accuracy: 0.9124 - val_loss: 0.1497 - val_accuracy: 0.9564\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1646 - accuracy: 0.9532 - val_loss: 0.1252 - val_accuracy: 0.9670\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1352 - accuracy: 0.9635 - val_loss: 0.1121 - val_accuracy: 0.9720\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1224 - accuracy: 0.9690 - val_loss: 0.1019 - val_accuracy: 0.9748\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1161 - accuracy: 0.9713 - val_loss: 0.1089 - val_accuracy: 0.9752\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1093 - accuracy: 0.9726 - val_loss: 0.1057 - val_accuracy: 0.9764\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1091 - accuracy: 0.9754 - val_loss: 0.1163 - val_accuracy: 0.9764\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0970 - accuracy: 0.9763 - val_loss: 0.1157 - val_accuracy: 0.9763\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0975 - accuracy: 0.9773 - val_loss: 0.1122 - val_accuracy: 0.9784\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.0929 - accuracy: 0.9797 - val_loss: 0.1217 - val_accuracy: 0.9771\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22e38660d90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_mnist_model()\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_log_dir\",\n",
    ")\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs=10,\n",
    "          validation_data=(val_images, val_labels),\n",
    "          callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-80252f7b8b496f5c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-80252f7b8b496f5c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /full_path_to_your_log_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Writing your own training and evaluation loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Training versus inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Low-level usage of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of values: 2.00\n"
     ]
    }
   ],
   "source": [
    "values = [0, 1, 2, 3, 4]\n",
    "mean_tracker = keras.metrics.Mean()\n",
    "for value in values:\n",
    "    mean_tracker.update_state(value)\n",
    "print(f\"Mean of values: {mean_tracker.result():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### A complete training and evaluation loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the training step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.RMSprop()\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    "loss_tracking_metric = keras.metrics.Mean()\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: resetting the metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step training loop: the loop itself**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9148\n",
      "...loss: 0.2914\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9535\n",
      "...loss: 0.1659\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9623\n",
      "...loss: 0.1421\n"
     ]
    }
   ],
   "source": [
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Writing a step-by-step evaluation loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9661\n",
      "...val_loss: 0.1350\n"
     ]
    }
   ],
   "source": [
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Make it fast with tf.function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Adding a `tf.function` decorator to our evaluation-step function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9661\n",
      "...val_loss: 0.1350\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "reset_metrics()\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items():\n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "### Leveraging fit() with a custom training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "**Implementing a custom training step to use with `fit()`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        loss_tracker.update_state(loss)\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.2974\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1675\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 3s 2ms/step - loss: 0.1395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22e49ff9790>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab_type": "code"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 0.2962 - sparse_categorical_accuracy: 0.9120\n",
      "Epoch 2/3\n",
      "1563/1563 [==============================] - 4s 2ms/step - loss: 0.1674 - sparse_categorical_accuracy: 0.9536\n",
      "Epoch 3/3\n",
      "1563/1563 [==============================] - 4s 3ms/step - loss: 0.1410 - sparse_categorical_accuracy: 0.9629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22e4a2a27c0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text"
   },
   "source": [
    "## Summary"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "chapter07_working-with-keras.i",
   "private_outputs": false,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
